{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaxx/cs5262-notebooks/blob/main/Crypto_Currency_Trading_Technical_Bias_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4bg8ebOYJLVN"
      },
      "source": [
        "# Background\n",
        "\n",
        "This is the data analysis effort for the network latency and loss project.  The notebook contains an analysis of the data we have collected, primarily looking at the data samples that were observed when running on AWS-based hardware in us-east-2 and us-west-2.\n",
        "\n",
        "## Observed Link Time\n",
        "\n",
        "As measured from us-west-2 to us-east-2:\n",
        "\n",
        "```\n",
        "PING x.xxx.xxx.xxx (x.xxx.xxx.xxx) 56(84) bytes of data.\n",
        "64 bytes from x.xxx.xxx.xxx: icmp_seq=1 ttl=105 time=48.4 ms\n",
        "64 bytes from x.xxx.xxx.xxx: icmp_seq=2 ttl=105 time=48.4 ms\n",
        "64 bytes from x.xxx.xxx.xxx: icmp_seq=3 ttl=105 time=48.4 ms\n",
        "64 bytes from x.xxx.xxx.xxx: icmp_seq=4 ttl=105 time=48.3 ms\n",
        "64 bytes from x.xxx.xxx.xxx: icmp_seq=5 ttl=105 time=48.3 ms\n",
        "64 bytes from x.xxx.xxx.xxx: icmp_seq=6 ttl=105 time=48.3 ms\n",
        "64 bytes from x.xxx.xxx.xxx: icmp_seq=7 ttl=105 time=48.3 ms\n",
        "64 bytes from x.xxx.xxx.xxx: icmp_seq=8 ttl=105 time=48.3 ms\n",
        "64 bytes from x.xxx.xxx.xxx: icmp_seq=9 ttl=105 time=49.4 ms\n",
        "```\n",
        "\n",
        "Similar times were observed when measuring from us-east-2 to us-west-2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries we will need\n",
        "\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_dataset(file_prefix):\n",
        "    if os.path.exists(f'{file_prefix}.parquet'):\n",
        "        df = pd.read_parquet(f'{file_prefix}.parquet')\n",
        "    else:\n",
        "        df = pd.read_json(f'{file_prefix}.json', orient='values')\n",
        "        # Rename the input columns\n",
        "        df.rename(columns = {0 : 'id', 1 : 'time_recv', 2 : 'latency', 3 : 'trade'}, inplace = True)\n",
        "        if 'trade' in df:\n",
        "            df['seq_no'] = df['trade'].map(lambda x: x['seq_no'])\n",
        "            df['time_sent'] = df['trade'].map(lambda x: x['timestamp'])\n",
        "            df['symbol'] = df['trade'].map(lambda x: x['symbol'])\n",
        "            del df['trade']\n",
        "\n",
        "        df['offset'] = df['time_recv'] - min(df['time_sent'])\n",
        "        df.to_parquet(f'{file_prefix}.parquet', engine='fastparquet')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the various TCP datasets\n",
        "df_us_east_tcp_1 = load_dataset('./data-us-east-2-tcp-1')\n",
        "df_us_east_tcp_2 = load_dataset('./data-us-east-2-tcp-2')\n",
        "df_us_east_tcp_4 = load_dataset('./data-us-east-2-tcp-4')\n",
        "df_us_east_tcp_6 = load_dataset('./data-us-east-2-tcp-6')\n",
        "df_us_east_tcp_8 = load_dataset('./data-us-east-2-tcp-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_latency(df):\n",
        "    id_list = df['id'].unique()\n",
        "    for id in id_list:\n",
        "        dv = df[df['id'] == id]\n",
        "        dv.loc[:, ('latency_ms')] = (dv.loc[:,('latency')] / 1000)\n",
        "        dq = dv.rolling(window = 10000, step = 1000).agg({\n",
        "            'offset': ['min', 'max'],\n",
        "            'latency_ms': ['min', 'max', 'mean']\n",
        "        })\n",
        "\n",
        "        #plt.plot((dv['offset'] / 1000), dv['latency_ms'], label = id)\n",
        "        plt.plot((dq[('offset', 'min')] / 1000), dq[('latency_ms', 'mean')], label = f'{id} (mean)')\n",
        "        #plt.plot((dq[('offset', 'min')] / 1000), dq[('latency_ms', 'max')], label = f'{id} (max)')\n",
        "        #plt.plot((dq[('offset', 'min')] / 1000), dq[('latency_ms', 'min')], label = f'{id} (min)')\n",
        "\n",
        "        print((dq[('latency_ms','max')]).mean())\n",
        "        #print((dq[dq[('offset', 'min')] > 1000000][('latency_ms','mean')]).mean())\n",
        "        #print((dq[dq[('offset', 'min')] > 1000000][('latency_ms','min')]).mean())\n",
        "\n",
        "    plt.title('Latency over time')\n",
        "    plt.xlabel('Time (ms)')\n",
        "    plt.ylabel('Latency (ms)')\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_us_east_tcp_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_us_east_tcp_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_us_east_tcp_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_us_east_tcp_6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_us_east_tcp_8)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UDP Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the various TCP datasets\n",
        "df_udp_1 = load_dataset('./data-us-east-2-udp-1')\n",
        "df_udp_2 = load_dataset('./data-us-east-2-udp-2')\n",
        "df_udp_4 = load_dataset('./data-us-east-2-udp-4')\n",
        "df_udp_6 = load_dataset('./data-us-east-2-udp-6')\n",
        "df_udp_8 = load_dataset('./data-us-east-2-udp-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_udp_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_udp_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_udp_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_udp_6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_latency(df_udp_8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_loss(df, symbol):\n",
        "    df_sorted = df.sort_values('seq_no')\n",
        "    df_sorted['pseq_no'] = (df_sorted['seq_no'].shift(1))\n",
        "    df_sorted['gap'] = (df_sorted['seq_no'] - df_sorted['pseq_no'])\n",
        "    df_sorted['loss'] = df_sorted['gap'].apply(lambda x: 1 if x > 1 else 0)\n",
        "\n",
        "    #df_test = df_sorted[(df_sorted['seq_no'] >= 240) & (df_sorted['seq_no'] <= 2055)]\n",
        "    #display(df_test)\n",
        "\n",
        "    min_time = df['time_sent'].min()\n",
        "\n",
        "    #print(df_sorted[df_sorted['gap'] > 1]['gap'].head())\n",
        "    #print(df_sorted[df_sorted['gap'] < 0]['gap'].head())\n",
        "\n",
        "    rolling = df_sorted.rolling(window = 1000, step = 100)\n",
        "    rolling = rolling.agg({'time_sent': ['min'], 'pseq_no': ['min'], 'seq_no': ['min', 'max'], 'gap': ['sum', 'max', 'count'], 'loss': [ 'sum', 'count' ]}).reset_index()\n",
        "    rolling['segment_size'] = (rolling['seq_no']['max'] - rolling['pseq_no']['min'])\n",
        "    rolling['segment_recv'] = rolling[('gap','count')]\n",
        "    rolling['segment_loss'] = (1.0 - rolling['segment_recv'] / rolling['segment_size'])\n",
        "    rolling['maximum_loss'] = rolling[('gap', 'max')]\n",
        "    rolling['meta_loss'] = (rolling[('loss', 'sum')] / rolling[('loss', 'count')])\n",
        "    rolling['time'] = (rolling['time_sent']['min'] - min_time)\n",
        "\n",
        "    #print(rolling['time_sent'] < 0.0)\n",
        "    #print(rolling[rolling['gap']['sum'] > 0])\n",
        "\n",
        "    #display(rolling.head())\n",
        "\n",
        "    rolling_2 = rolling.rolling(window = 10000, step = 10000).agg({\n",
        "        ('time', ''): ['min'],\n",
        "        ('segment_loss', ''): ['mean']\n",
        "    })\n",
        "\n",
        "    rolling_2 = rolling_2.rename(\n",
        "        columns={\n",
        "            ('time', '', 'min'): 'time',\n",
        "            ('segment_loss', '', 'mean'): 'segment_loss'\n",
        "        })\n",
        "    \n",
        "    plt.plot((rolling['time'] / 1000), (100.0 * rolling['meta_loss']), label = f'{symbol} (meta loss)')\n",
        "    #plt.plot((rolling['time'] / 1000), (100.0 * rolling['segment_loss']), label = f'{symbol} (mean loss)')\n",
        "\n",
        "def plot_max_loss(df, symbol):\n",
        "    df_sorted = df.sort_values('seq_no')\n",
        "    df_sorted['pseq_no'] = (df_sorted['seq_no'].shift(1))\n",
        "    df_sorted['gap'] = (df_sorted['seq_no'] - df_sorted['pseq_no'])\n",
        "\n",
        "    min_time = df['time_sent'].min()\n",
        "\n",
        "    rolling = df_sorted.rolling(window = 1000, step = 100)\n",
        "    rolling = rolling.agg({'time_sent': ['min'], 'pseq_no': ['min'], 'seq_no': ['min', 'max'], 'gap': ['sum', 'max', 'count']}).reset_index()\n",
        "    rolling['segment_size'] = (rolling['seq_no']['max'] - rolling['pseq_no']['min'])\n",
        "    rolling['segment_recv'] = rolling[('gap','count')]\n",
        "    rolling['segment_loss'] = (1.0 - rolling['segment_recv'] / rolling['segment_size'])\n",
        "    rolling['maximum_loss'] = rolling[('gap', 'max')]\n",
        "    rolling['time'] = (rolling['time_sent']['min'] - min_time)\n",
        "\n",
        "    plt.plot((rolling['time'] / 1000), rolling['maximum_loss'], label = f'{symbol} (maximum loss)')\n",
        "\n",
        "def plot_loss_for_sender(df, sender_id):\n",
        "    sym_list = df['symbol'].unique()\n",
        "    for symbol in sym_list:\n",
        "        dfx = df[df['symbol'] == symbol]\n",
        "        plot_loss(dfx, symbol)\n",
        "\n",
        "    plt.title(f'{sender_id}')\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    plt.xlabel('Time (ms)')\n",
        "    plt.ylabel('% Data Loss')\n",
        "    plt.show()\n",
        "\n",
        "    sym_list = df['symbol'].unique()\n",
        "    for symbol in sym_list:\n",
        "        dfx = df[df['symbol'] == symbol]\n",
        "        plot_max_loss(dfx, symbol)\n",
        "\n",
        "    plt.title(f'{sender_id}')\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    plt.xlabel('Time (ms)')\n",
        "    plt.ylabel('Messages Lost')\n",
        "    plt.ticklabel_format(style='plain', axis='y')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_loss_for_all(df):\n",
        "    id_list = df['id'].unique()\n",
        "    for id in id_list:\n",
        "        dfx = df[df['id'] == id]\n",
        "        plot_loss_for_sender(dfx, id)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_loss_for_all(df_udp_1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_latency_svg(df):\n",
        "    df_symbol = df[df['symbol'] == 'AAPL']\n",
        "    df_sorted = df_symbol.sort_values('seq_no')\n",
        "    df_sorted['pseq_no'] = (df_sorted['seq_no'].shift(1))\n",
        "    df_sorted['gap'] = (df_sorted['seq_no'] - df_sorted['pseq_no'])\n",
        "\n",
        "    df_sorted = df_sorted[df_sorted['seq_no'] < 10000]\n",
        "\n",
        "    #display(df_sorted[(df_sorted['pseq_no'] >= 100) & (df_sorted['seq_no'] <= 6392)].head(1000))\n",
        "\n",
        "    start_seq = 0\n",
        "    end_seq = df_sorted['seq_no'].max()\n",
        "\n",
        "    height=1000\n",
        "\n",
        "    print(f'<svg viewBox=\"0 0 {end_seq} {height}\" xmlns=\"http://www.w3.org/2000/svg\">')\n",
        "\n",
        "    for index, row in df_sorted[(df_sorted['gap'] > 1)].iterrows():\n",
        "        pseq_no = row['pseq_no']\n",
        "        cseq_no = row['seq_no']\n",
        "        gap = cseq_no - pseq_no\n",
        "\n",
        "        print(f'<rect x=\"{start_seq}\" y=\"0\" width=\"{pseq_no - start_seq}\" height=\"{height}\" fill=\"green\" stroke=\"black\" stroke-width=\"0.25\" />')\n",
        "        print(f'<rect x=\"{pseq_no}\" y=\"0\" width=\"{cseq_no - pseq_no}\" height=\"{height}\" fill=\"#7c0a02\" stroke=\"black\" stroke-width=\"0.25\"/>')\n",
        "        start_seq = cseq_no\n",
        "\n",
        "    print('</svg>')\n",
        "\n",
        "print_latency_svg(df_udp_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_loss_for_all(df_udp_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_loss_for_all(df_udp_4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_loss_for_all(df_udp_6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_loss_for_all(df_udp_8)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN+Zgt4uTWdcdgnBSsS7wrF",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Crypto Currency Trading Technical Bias Analysis",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
